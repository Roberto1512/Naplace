# MACHINE LEARNING CANVAS

**Designed For:** Issue Report Classification w/Mozilla  
**Designed By:** Naplace  
**Date:** 15/10/2025  
**Iteration:** 1

**Prediction Task**

The project focuses on developing and evaluating advanced machine learning models for the automatic classification of Mozilla bug reports. Each prediction is made on a single bug report submitted through Mozilla's issue tracking system.

The goal is to automatically identify both the main software component affected by the issue and its corresponding sub-component within Mozilla's hierarchical component structure. Once a new report is received, the model predicts the most likely component and routes or suggests it to the appropriate development team for verification and resolution.

The classification task follows a two-layer hierarchy, with nine main categories at the first level (for example, Core, Firefox, Toolkit, etc.) and more granular sub-components at the second level.

**Decisions**

The predictions generated by the model are used to automatically assign each bug report to the most relevant development team. When a new issue is submitted, the system identifies the most probable component and routes or suggests the report to the corresponding team responsible for that area.

This automation significantly reduces triage time and minimizes human error in the routing process. Every automatic decision can still be reviewed or confirmed by Mozilla maintainers, ensuring reliability and full human oversight within the workflow.

**Value Proposition**

The main beneficiaries of the system are Mozilla developers, triage teams, and project maintainers, who handle thousands of issue reports across multiple components. Currently, each new bug must be manually assigned to the correct component, a process that is both time-consuming and prone to human error.

By introducing an ML-based approach, the classification of bug reports becomes automatic, reducing manual workload and improving the efficiency and precision of issue routing. When model confidence is high, the report can be automatically assigned to the appropriate team, while still allowing human review when necessary.

The solution integrates seamlessly into the existing Bugzilla and BugBug frameworks, presenting component suggestions directly within the bug creation or triage interface.

**Data Collection**

The dataset is derived from Mozilla's Bugzilla platform, containing bug reports manually labeled with their corresponding components. Each report includes an ID, title, and description, which are used as input features.

Data are automatically extracted and preprocessed through the BugBug framework, ensuring updated and consistent labeling. Text cleaning and normalization are applied before training. The main challenge is the class imbalance, which will be mitigated using appropriate data-splitting and few-shot learning strategies.

**Data Sources**

Data are obtained from Mozilla's Bugzilla database through the BugBug framework, which provides access to labeled bug reports. Each record includes the bug ID, title, description, and the corresponding component label as defined in the component.py ruleset.

The dataset used for training is built directly from this source, ensuring consistency with Mozilla's existing classification system.

**Impact Simulation**

The main advantage of the system is faster bug resolution, as assignment is automated. However, incorrect predictions require teams to manually identify and reassign the correct component, increasing resolution time. Low model confidence also triggers manual triage.

To simulate pre-deployment, the dataset will be split so that unseen data (the test set) can be used to evaluate model performance. Deployment criteria are based on achieving measurable improvements over Mozilla's current BugBug baseline model.

Since the task involves technical report classification and no human subjects, fairness constraints are not relevant, and the risk of discrimination is minimal.

**Making Predictions**

Predictions are generated in batch mode, processing newly collected bug reports at regular intervals rather than immediately after submission. Inference runs on CPU environments, while model training and fine-tuning use GPU resources to improve efficiency.

Each batch requires only a few minutes to produce component predictions for the incoming reports. The system contributes to faster triage, quicker resolution times, and a more effective open-source development workflow.

**Building Models**

The system adopts a hierarchical classification strategy. A first model predicts the main component, and for each of these components, a dedicated sub-model predicts the corresponding sub-component.

Training is performed on GPU environments for efficiency, while inference runs on CPU. Models are periodically updated as new labeled data become available or when performance decreases.

Current baseline results, which the project aims to improve, show an accuracy of approximately 0.66 and a macro-F1 score of about 0.55.

**Features**

The main features are extracted from the text content of bug reports, including the title, description, and relevant keywords. Additional metadata such as historical bug counts per component are used to enrich the representation.

Text data are preprocessed, tokenized, and vectorized for model input. Future improvements may include data augmentation and new feature types to enhance performance on underrepresented classes.

**Monitoring** 

System performance is tracked using standard metrics such as Accuracy, Precision, Recall, and F1-score.
Monitoring is continuous and updated after each retraining or dataset refresh to detect performance drift.
Operational indicators, including triage time reduction and correct assignment rate, are also reviewed to ensure long-term model stability and effectiveness.
